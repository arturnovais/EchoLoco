import os
import streamlit as st
from utils.audio import (
    transcribe_audio,
    tts_audio,
    chat_completion,
    verify_speaker,
    upload_audio_to_gcs,
)

st.set_page_config(page_title="Chatbot de Voz", page_icon=":microphone:")

st.title("ğŸ—£ï¸ Chatbot de Voz Personalizado")

# -----------------------------------------------------------------------------
# Barra lateral â€“ reiniciar conversa + ajustes avanÃ§ados
# -----------------------------------------------------------------------------
if st.sidebar.button("ğŸ”„ Nova conversa"):
    st.session_state.clear()
    st.rerun()

# Expander discreto para ajustes avanÃ§ados
with st.sidebar.expander("âš™ï¸ Ajustes avanÃ§ados", expanded=False):
    threshold_default = st.session_state.get("threshold", 0.1)
    threshold_str = st.text_input(
        "Threshold de verificaÃ§Ã£o (0.1 â€“ 0.9)",
        value=f"{threshold_default:.2f}",
        help="Aumente para exigir coincidÃªncia mais exata; diminua para ser mais permissivo.",
    )
    try:
        threshold_value = float(threshold_str)
        if not 0.1 <= threshold_value <= 0.9:
            raise ValueError
    except ValueError:
        st.warning("Por favor, digite um nÃºmero entre 0.1 e 0.9")
        threshold_value = threshold_default

# Salva o threshold escolhido na sessÃ£o
st.session_state["threshold"] = threshold_value

# -----------------------------------------------------------------------------
# Estado da sessÃ£o â€“ histÃ³rico + contador para widget de Ã¡udio
# -----------------------------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": (
                "VocÃª Ã© um assistente de voz que se adapta a cada usuÃ¡rio. "
                "Exagere nos detalhes e na personalizaÃ§Ã£o sempre que possÃ­vel."
            ),
        }
    ]

# contador que gera chaves Ãºnicas para o widget de gravaÃ§Ã£o
if "audio_key" not in st.session_state:
    st.session_state.audio_key = 0  # serÃ¡ incrementado apÃ³s cada gravaÃ§Ã£o

# -----------------------------------------------------------------------------
# Exibe todo o histÃ³rico jÃ¡ trocado
# -----------------------------------------------------------------------------
for msg in st.session_state.messages:
    role = msg["role"]
    if role == "assistant":
        with st.chat_message("assistant"):
            st.write(msg["content"])
            # Reexibe Ã¡udio da resposta, se existir (previne erros de midia)
            if msg.get("audio_bytes") is not None:
                st.audio(msg["audio_bytes"], format=msg.get("mime", "audio/wav"))
    elif role == "user":
        with st.chat_message("user"):
            if msg.get("speaker_name"):
                st.markdown(
                    f"*UsuÃ¡rio identificado: **{msg['speaker_name']}***",
                    unsafe_allow_html=False,
                )
            elif msg.get("identified") is False:
                st.markdown(
                    "*UsuÃ¡rio nÃ£o identificado â€“ usando perfil padrÃ£o*",
                    unsafe_allow_html=False,
                )
            st.write(msg["content"])

# -----------------------------------------------------------------------------
# Entrada de voz (rodapÃ©) â€“ usa chave Ãºnica a cada ciclo
# -----------------------------------------------------------------------------
widget_key = f"mic_{st.session_state.audio_key}"
audio_file = st.audio_input(
    "Segure e faleâ€¦",
    key=widget_key,
    label_visibility="collapsed",
)

# -----------------------------------------------------------------------------
# Processa nova mensagem de voz (se houver)
# -----------------------------------------------------------------------------
if audio_file is not None:
    with st.spinner("ğŸ“¤ Enviando Ã¡udioâ€¦"):
        gs_uri, tmp_path = upload_audio_to_gcs(audio_file, dest_prefix="audio")

    try:
        # IdentificaÃ§Ã£o do locutor usando threshold configurÃ¡vel
        with st.spinner("ğŸ” Identificando usuÃ¡rioâ€¦"):
            speaker_info = verify_speaker(
                uploaded_file=audio_file,
                gs_uri=gs_uri,
                threshold=st.session_state["threshold"],
            )

        # TranscriÃ§Ã£o
        with st.spinner("ğŸ” Transcrevendoâ€¦"):
            user_text = transcribe_audio(uploaded_file=None, gs_uri=gs_uri)

        # Mostra o que o usuÃ¡rio disse
        with st.chat_message("user"):
            if speaker_info and speaker_info.get("found_in_bq"):
                st.markdown(
                    f"*UsuÃ¡rio identificado: **{speaker_info['speaker_name']}***",
                    unsafe_allow_html=False,
                )
            else:
                st.markdown(
                    "*UsuÃ¡rio nÃ£o identificado â€“ usando perfil padrÃ£o*",
                    unsafe_allow_html=False,
                )
            st.write(user_text)

        # Atualiza histÃ³rico (UI)
        if speaker_info and speaker_info.get("found_in_bq"):
            st.session_state.messages.append(
                {
                    "role": "user",
                    "content": user_text,
                    "speaker_name": speaker_info["speaker_name"],
                }
            )
            formatted_user_content = (
                f"A mensagem estÃ¡ sendo enviada pelo {speaker_info['speaker_name']}. "
                f"InstruÃ§Ãµes: {speaker_info.get('instructions', '')}. "
                f"Mensagem: {user_text}"
            )
        else:
            st.session_state.messages.append(
                {"role": "user", "content": user_text, "identified": False}
            )
            formatted_user_content = (
                "A mensagem estÃ¡ sendo enviada por um usuÃ¡rio nÃ£o identificado. "
                "InstruÃ§Ãµes: Responda de forma amigÃ¡vel e genÃ©rica. "
                f"Mensagem: {user_text}"
            )

        # Prepara todo o histÃ³rico para o LLM (sem truncar)
        history_for_llm = [
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ]
        # Substitui o conteÃºdo da Ãºltima mensagem do usuÃ¡rio por versÃ£o personalizada
        history_for_llm[-1]["content"] = formatted_user_content

        # Chama o LLM
        with st.spinner("ğŸ¤– Pensandoâ€¦"):
            assistant_reply = chat_completion(history_for_llm)

        # ConfiguraÃ§Ãµes de voz
        voice_settings = {
            "stability": 0.25,
            "similarity_boost": 0.9,
            "use_speaker_boost": True,
            "style": 0.4,
            "speed": 1,
        }

        # Guarda e mostra a resposta
        with st.spinner("ğŸ™ï¸ Gerando vozâ€¦"):
            audio_bytes, mime = tts_audio(
                assistant_reply,
                provider="elevenlabs",
                voice_id="ttLrPNfZdNBtVDeOUJsm",
                voice_settings=voice_settings,
            )

        st.session_state.messages.append(
            {
                "role": "assistant",
                "content": assistant_reply,
                "audio_bytes": audio_bytes,
                "mime": mime,
            }
        )

        # Exibe no chat
        with st.chat_message("assistant"):
            st.write(assistant_reply)
            st.audio(audio_bytes, format=mime)

    finally:
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path)
        # ------------------------------------------------------------------
        # Prepara a prÃ³xima gravaÃ§Ã£o: incrementa a chave e faz rerun
        # ------------------------------------------------------------------
        st.session_state.audio_key += 1
        st.rerun()